<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>TensorFlow.js Model Testing - Revised</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.22.0/tf.min.js"></script>
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 20px;
        line-height: 1.6;
      }
      .container {
        max-width: 800px;
        margin: 0 auto;
      }
      h1 {
        color: #333;
      }
      #output {
        background-color: #f5f5f5;
        border: 1px solid #ddd;
        padding: 15px;
        border-radius: 5px;
        margin: 20px 0;
        white-space: pre-wrap;
        font-family: monospace;
        max-height: 500px;
        overflow-y: auto;
      }
      .test-panel {
        margin-bottom: 20px;
        padding: 15px;
        border: 1px solid #ddd;
        border-radius: 5px;
      }
      .form-group {
        margin-bottom: 10px;
      }
      .form-group label {
        display: block;
        margin-bottom: 5px;
        font-weight: bold;
      }
      button {
        background-color: #4caf50;
        color: white;
        padding: 10px 15px;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        margin-top: 10px;
        margin-right: 5px;
      }
      button:hover {
        background-color: #45a049;
      }
      .info-box {
        background-color: #e7f3fe;
        border-left: 6px solid #2196f3;
        padding: 10px;
        margin: 20px 0;
      }
      .success {
        color: #4caf50;
        font-weight: bold;
      }
      .error {
        color: #f44336;
        font-weight: bold;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>TensorFlow.js Model Testing - Revised</h1>

      <div class="info-box">
        <p>
          <strong>Penting:</strong> Berdasarkan error sebelumnya, halaman ini
          menggunakan metode <code>model.execute()</code> alih-alih
          <code>model.executeAsync()</code> dan secara eksplisit menentukan
          output <code>"Identity"</code>.
        </p>
      </div>

      <div class="test-panel">
        <h2>Model Information</h2>
        <div class="form-group">
          <label for="modelPath">Model Path:</label>
          <input
            type="text"
            id="modelPath"
            value="http://127.0.0.1:5500/tfjs_model_v3/model.json"
            style="width: 100%"
          />
        </div>
        <button id="loadModelBtn">Load Model</button>
        <button id="inspectModelBtn">Inspect Model</button>
      </div>

      <div class="test-panel">
        <h2>Custom Input Test with model.execute()</h2>
        <div class="form-group">
          <label for="customInput">Input Data (comma separated values):</label>
          <input
            type="text"
            id="customInput"
            value="1.0, 2.0, 3.0"
            placeholder="e.g. 1.0, 2.0, 3.0"
          />
        </div>
        <div class="form-group">
          <label>Input Format:</label>
          <select id="inputFormat">
            <option value="direct">Direct Tensor</option>
            <option value="named">Named Input ("inputs")</option>
            <option value="specificNamed">Specific Named ("inputs:0")</option>
          </select>
        </div>
        <div class="form-group">
          <label for="outputNode">Output Node:</label>
          <input
            type="text"
            id="outputNode"
            value="Identity"
            placeholder="e.g. Identity"
          />
        </div>
        <button id="runCustomTestBtn">Run Test</button>
      </div>

      <div class="test-panel">
        <h2>Batch Input Test</h2>
        <div class="form-group">
          <label for="batchInput"
            >Batch Input Data (one row per line, values comma separated):</label
          >
          <textarea id="batchInput" rows="5" style="width: 100%">
1.0, 2.0, 3.0
4.0, 5.0, 6.0
7.0, 8.0, 9.0</textarea
          >
        </div>
        <button id="runBatchTestBtn">
          Run Batch Test with model.execute()
        </button>
      </div>

      <div class="test-panel">
        <h2>Test All Methods</h2>
        <p>
          This will try multiple approaches: model.execute(),
          model.executeAsync(), and model.predict()
        </p>
        <button id="testAllMethodsBtn">Test All Methods</button>
      </div>

      <div class="test-panel">
        <h2>Auto-Detect Configuration</h2>
        <p>Will attempt to auto-detect correct input/output configuration</p>
        <button id="autoDetectBtn">Auto-Detect Working Configuration</button>
      </div>

      <h2>Output:</h2>
      <div id="output">Console output will appear here</div>
    </div>

    <script>
      // Variable to store the loaded model
      let model = null;

      // Function to log to the output div
      function log(message) {
        const output = document.getElementById("output");
        output.textContent += message + "\n";
        output.scrollTop = output.scrollHeight;
      }

      // Clear the log
      function clearLog() {
        document.getElementById("output").textContent = "";
      }

      // Redirect console output to our log
      const originalConsoleLog = console.log;
      const originalConsoleError = console.error;

      console.log = function () {
        const message = Array.from(arguments).join(" ");
        log(message);
        originalConsoleLog.apply(console, arguments);
      };

      console.error = function () {
        const message = "ERROR: " + Array.from(arguments).join(" ");
        log(message);
        originalConsoleError.apply(console, arguments);
      };

      // Function to load the model
      async function loadModel() {
        clearLog();

        const modelPath = document.getElementById("modelPath").value;
        console.log(`Loading model from: ${modelPath}`);

        try {
          model = await tf.loadGraphModel(modelPath);
          console.log("Model loaded successfully!");
          console.log("TensorFlow.js version:", tf.version.tfjs);

          // Basic model inspection
          console.log("Number of inputs:", model.inputs.length);
          if (model.inputs.length > 0) {
            console.log("Model input name:", model.inputs[0].name);
            console.log("Model input shape:", model.inputs[0].shape);
          }

          console.log("Number of outputs:", model.outputs.length);
          if (model.outputs.length > 0) {
            console.log("Model output name:", model.outputs[0].name);
            console.log("Model output shape:", model.outputs[0].shape);
          }

          return true;
        } catch (error) {
          console.error("Failed to load model:", error.message);
          model = null;
          return false;
        }
      }

      // Function to inspect model in detail
      async function inspectModel() {
        if (!model) {
          console.error("Model not loaded. Please load the model first.");
          return;
        }

        clearLog();
        console.log("=== Detailed Model Inspection ===");

        // Input nodes
        console.log("\nINPUT NODES:");
        model.inputs.forEach((node, i) => {
          console.log(
            `${i + 1}. Name: "${node.name}", Shape: [${node.shape}], Dtype: ${
              node.dtype
            }`
          );
        });

        // Output nodes
        console.log("\nOUTPUT NODES:");
        model.outputs.forEach((node, i) => {
          console.log(
            `${i + 1}. Name: "${node.name}", Shape: [${node.shape}], Dtype: ${
              node.dtype
            }`
          );
        });

        // Model signatures (if available)
        if (model.signature) {
          console.log("\nMODEL SIGNATURE:");
          console.log(JSON.stringify(model.signature, null, 2));
        } else {
          console.log("\nNo model signature available");
        }

        // Try to get model JSON
        try {
          const modelConfig = await model.getConfig();
          console.log("\nMODEL CONFIG:");
          console.log(JSON.stringify(modelConfig, null, 2));
        } catch (error) {
          console.log("\nCannot get model config:", error.message);
        }

        console.log("\nModel inspection complete.");
      }

      // Function to parse input values
      function parseInputValues(inputString) {
        return inputString.split(",").map((val) => parseFloat(val.trim()));
      }

      // Function to parse batch input values
      function parseBatchInput(batchInputString) {
        return batchInputString
          .split("\n")
          .filter((line) => line.trim() !== "")
          .map((line) => parseInputValues(line));
      }

      // Function to run custom test with model.execute()
      async function runCustomTest() {
        if (!model) {
          console.error("Model not loaded. Please load the model first.");
          return;
        }

        clearLog();
        console.log("Running custom test with model.execute()...");

        const inputValues = parseInputValues(
          document.getElementById("customInput").value
        );
        const formatType = document.getElementById("inputFormat").value;
        const outputNode = document.getElementById("outputNode").value.trim();

        if (inputValues.length !== 3) {
          console.error("Input must have exactly 3 values.");
          return;
        }

        console.log("Input values:", inputValues);
        console.log("Format type:", formatType);
        console.log("Output node:", outputNode);

        try {
          let input, prediction;

          // Create tensor
          input = tf.tensor2d([inputValues], [1, 3]);
          console.log("Input shape:", input.shape);

          // Execute based on format type
          switch (formatType) {
            case "direct":
              console.log("Using direct tensor input");
              prediction = model.execute(input, outputNode);
              break;
            case "named":
              console.log("Using named input ('inputs')");
              prediction = model.execute({ inputs: input }, outputNode);
              break;
            case "specificNamed":
              console.log("Using specific named input ('inputs:0')");
              prediction = model.execute({ "inputs:0": input }, outputNode);
              break;
          }

          logPredictionInfo(prediction, "Custom test");

          // Clean up tensors
          tf.dispose([input, prediction]);
        } catch (error) {
          console.error("Error running custom test:", error.message);
        }
      }

      // Function to run batch test with model.execute()
      async function runBatchTest() {
        if (!model) {
          console.error("Model not loaded. Please load the model first.");
          return;
        }

        clearLog();
        console.log("Running batch test with model.execute()...");

        const batchInputValues = parseBatchInput(
          document.getElementById("batchInput").value
        );
        const outputNode = document.getElementById("outputNode").value.trim();

        // Check if all rows have exactly 3 values
        if (!batchInputValues.every((row) => row.length === 3)) {
          console.error("Each input row must have exactly 3 values.");
          return;
        }

        console.log(`Batch size: ${batchInputValues.length} samples`);
        console.log("Batch values:", batchInputValues);
        console.log("Output node:", outputNode);

        try {
          // Create tensor
          const input = tf.tensor2d(batchInputValues);
          console.log("Input shape:", input.shape);

          // Execute model
          const prediction = model.execute(input, outputNode);

          logPredictionInfo(prediction, "Batch test");

          // Clean up tensors
          tf.dispose([input, prediction]);
        } catch (error) {
          console.error("Error running batch test:", error.message);
        }
      }

      // Function to test all methods (execute, executeAsync, predict)
      async function testAllMethods() {
        if (!model) {
          const loaded = await loadModel();
          if (!loaded) return;
        }

        clearLog();
        console.log("Testing all methods with single input [1.0, 2.0, 3.0]...");

        const input = tf.tensor2d([[1.0, 2.0, 3.0]], [1, 3]);
        console.log("Input shape:", input.shape);

        // For tracking which methods succeed
        const results = {
          executeWithoutOutput: false,
          executeWithOutput: false,
          executeAsync: false,
          predict: false,
        };

        // 1. Try model.execute() without specifying output
        console.log(
          "\n--- METHOD 1: model.execute() without specifying output ---"
        );
        try {
          const result = model.execute(input);
          logPredictionInfo(result, "model.execute() without output");
          results.executeWithoutOutput = true;
          result.dispose();
        } catch (err) {
          console.error(
            "Error with model.execute() without output:",
            err.message
          );
        }

        // 2. Try model.execute() with Identity output
        console.log("\n--- METHOD 2: model.execute() with Identity output ---");
        try {
          const result = model.execute(input, "Identity");
          logPredictionInfo(result, "model.execute() with Identity output");
          results.executeWithOutput = true;
          result.dispose();
        } catch (err) {
          console.error(
            "Error with model.execute() with Identity output:",
            err.message
          );
        }

        // 3. Try model.executeAsync()
        console.log("\n--- METHOD 3: model.executeAsync() ---");
        try {
          const result = await model.executeAsync(input);
          logPredictionInfo(result, "model.executeAsync()");
          results.executeAsync = true;
          result.dispose();
        } catch (err) {
          console.error("Error with model.executeAsync():", err.message);
        }

        // 4. Try model.predict()
        console.log("\n--- METHOD 4: model.predict() ---");
        try {
          const result = model.predict(input);
          logPredictionInfo(result, "model.predict()");
          results.predict = true;
          result.dispose();
        } catch (err) {
          console.error("Error with model.predict():", err.message);
        }

        // Summary of results
        console.log("\n=== SUMMARY OF RESULTS ===");
        console.log(
          "model.execute() without output:",
          results.executeWithoutOutput ? "✅ SUCCESS" : "❌ FAILED"
        );
        console.log(
          "model.execute() with Identity output:",
          results.executeWithOutput ? "✅ SUCCESS" : "❌ FAILED"
        );
        console.log(
          "model.executeAsync():",
          results.executeAsync ? "✅ SUCCESS" : "❌ FAILED"
        );
        console.log(
          "model.predict():",
          results.predict ? "✅ SUCCESS" : "❌ FAILED"
        );

        input.dispose();
      }

      // Function to auto-detect working configuration
      async function autoDetectConfig() {
        if (!model) {
          const loaded = await loadModel();
          if (!loaded) return;
        }

        clearLog();
        console.log("Auto-detecting working configuration...");

        // Get input and output node names
        const inputNodeNames = model.inputs.map((node) => node.name);
        const outputNodeNames = model.outputs.map((node) => node.name);

        console.log("Input node names:", inputNodeNames);
        console.log("Output node names:", outputNodeNames);

        const sampleData = tf.tensor2d([[1.0, 2.0, 3.0]], [1, 3]);
        console.log("Sample data shape:", sampleData.shape);

        // Try different combinations
        console.log("\nTrying different input/output combinations...");

        let successfulConfigs = [];

        // Try the most likely configurations first
        const testConfigs = [
          {
            method: "execute",
            inputFormat: "direct",
            outputNode: null,
          },
          {
            method: "execute",
            inputFormat: "direct",
            outputNode: "Identity",
          },
          {
            method: "execute",
            inputFormat: "named:inputs",
            outputNode: "Identity",
          },
          {
            method: "execute",
            inputFormat: "named:inputs:0",
            outputNode: "Identity",
          },
          {
            method: "executeAsync",
            inputFormat: "direct",
            outputNode: null,
          },
          {
            method: "predict",
            inputFormat: "direct",
            outputNode: null,
          },
        ];

        // Add configurations for each input/output node
        for (const inputName of inputNodeNames) {
          for (const outputName of outputNodeNames) {
            testConfigs.push({
              method: "execute",
              inputFormat: `specific:${inputName}`,
              outputNode: outputName,
            });
          }
        }

        // Test each configuration
        for (const config of testConfigs) {
          console.log(
            `\nTrying: method=${config.method}, input=${
              config.inputFormat
            }, output=${config.outputNode || "default"}`
          );

          try {
            let input, result;

            // Prepare input based on format
            if (config.inputFormat === "direct") {
              input = sampleData;
            } else if (config.inputFormat === "named:inputs") {
              input = { inputs: sampleData };
            } else if (config.inputFormat === "named:inputs:0") {
              input = { "inputs:0": sampleData };
            } else if (config.inputFormat.startsWith("specific:")) {
              const inputName = config.inputFormat.split(":")[1];
              input = {};
              input[inputName] = sampleData;
            }

            // Execute model with appropriate method
            if (config.method === "execute") {
              result = model.execute(input, config.outputNode);
            } else if (config.method === "executeAsync") {
              result = await model.executeAsync(input);
            } else if (config.method === "predict") {
              result = model.predict(input);
            }

            // If we got here, it worked!
            console.log("✅ SUCCESS with this configuration!");
            console.log("Result shape:", result.shape);

            // Add to successful configs
            successfulConfigs.push({
              ...config,
              resultShape: result.shape,
            });

            result.dispose();
          } catch (err) {
            console.log("❌ This configuration failed:", err.message);
          }
        }
      }
      // // Summary of successful configurations
      // console.log("\n=== SUCCESSFUL CONFIGURATIONS ===");
      // if (successfulConfigs.length === 0) {
      //     console.log("No successful configurations found.");
      // } else {
      //     successfulConfigs.forEach((config, index) => {
      //         console.log(`\nConfiguration ${index + 1}:`);
      //         console.log(`- Method: model.${config.method}()`);
      //         console.log(`- Input format: ${config.inputFormat}`);
      //         console.log(`- Output node: ${config.outputNode || "default"}`);
      //         console.log(`- Result shape: [${config.resultShape}]`);

      //         // Generate sample code
      //         let sampleCode = "// Sample code for this configuration\n";

      //         // Input preparation
      //         sampleCode += "const inputData = tf.tensor2d([[1.0, 2.0, 3.0]], [1, 3]);\n";

      //         // Format input based on config
      //         let inputCode = "inputData";
    </script>
  </body>
</html>
